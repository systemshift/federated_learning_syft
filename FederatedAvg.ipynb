{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "tff.framework.set_default_context(tff.test.ReferenceExecutor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tff.federated_computation\n",
    "def hello_world():\n",
    "    return 'Hello World!'\n",
    "hello_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(dtype('uint8'), (60000, 28, 28)), (dtype('uint8'), (60000,))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x.dtype, x.shape) for x in mnist_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES_PER_USER = 1000\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "def get_data_for_digit(source, digit):\n",
    "    output_sequence = []\n",
    "    all_samples = [i for i, d in enumerate(source[1]) if d == digit]\n",
    "    for i in range(0, min(len(all_samples), NUM_EXAMPLES_PER_USER), BATCH_SIZE):\n",
    "        batch_samples = all_samples[i:i + BATCH_SIZE]\n",
    "        output_sequence.append({\n",
    "            'x':\n",
    "                np.array([source[0][i].flatten() / 255.0 for i in batch_samples], dtype=np.float32),\n",
    "            'y':\n",
    "                np.array([source[1][i] for i in batch_samples], dtype=np.int32)\n",
    "        })\n",
    "    return output_sequence\n",
    "\n",
    "federated_train_data = [get_data_for_digit(mnist_train, d) for d in range(10)]\n",
    "\n",
    "federated_test_data = [get_data_for_digit(mnist_test, d) for d in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "federated_train_data[5][-1]['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(federated_train_data[5][-1]['x'][-1].reshape(28, 28), cmap='gray')\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<x=float32[?,784],y=int32[?]>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SPEC = collections.OrderedDict(\n",
    "    x=tf.TensorSpec(shape=[None, 784], dtype=tf.float32),\n",
    "    y=tf.TensorSpec(shape=[None], dtype=tf.int32)\n",
    ")\n",
    "BATCH_TYPE = tff.to_type(BATCH_SPEC)\n",
    "\n",
    "str(BATCH_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<weights=float32[784,10],bias=float32[10]>\n"
     ]
    }
   ],
   "source": [
    "MODEL_SPEC = collections.OrderedDict(\n",
    "    weights=tf.TensorSpec(shape=[784, 10], dtype=tf.float32),\n",
    "    bias=tf.TensorSpec(shape=[10], dtype=tf.float32)\n",
    ")\n",
    "MODEL_TYPE = tff.to_type(MODEL_SPEC)\n",
    "\n",
    "print(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def forward_pass(model, batch):\n",
    "    predicted_y = tf.nn.softmax(\n",
    "        tf.matmul(batch['x'], model['weights']) + model['bias'])\n",
    "    return -tf.reduce_mean(\n",
    "        tf.reduce_sum(\n",
    "            tf.one_hot(batch['y'], 10) * tf.math.log(predicted_y), axis=[1]))\n",
    "\n",
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "def batch_loss(model, batch):\n",
    "    return forward_pass(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3025854"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_model = collections.OrderedDict(\n",
    "    weights=np.zeros([784, 10], dtype=np.float32),\n",
    "    bias=np.zeros([10], dtype=np.float32))\n",
    "\n",
    "sample_batch = federated_train_data[5][-1]\n",
    "\n",
    "batch_loss(initial_model, sample_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
    "def batch_train(initial_model, batch, learning_rate):\n",
    "    model_vars = collections.OrderedDict([\n",
    "        (name, tf.Variable(name=name, initial_value=value))\n",
    "        for name, value in initial_model.items()\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "    \n",
    "    @tf.function\n",
    "    def _train_on_batch(model_vars, batch):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = forward_pass(model_vars, batch)\n",
    "        grads = tape.gradient(loss, model_vars)\n",
    "        optimizer.apply_gradients(\n",
    "            zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)))\n",
    "        return model_vars\n",
    "    return _train_on_batch(model_vars, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.19690022, 0.13176315, 0.10113225, 0.08273812, 0.07030139]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = initial_model\n",
    "losses = []\n",
    "for _ in range(5):\n",
    "    model = batch_train(model, sample_batch, 0.1)\n",
    "    losses.append(batch_loss(model, sample_batch))\n",
    "\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
    "\n",
    "@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n",
    "def local_train(initial_model, learning_rate, all_batches):\n",
    "    @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "    def batch_fn(model, batch):\n",
    "        return batch_train(model, batch, learning_rate)\n",
    "    return tff.sequence_reduce(all_batches, initial_model, batch_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "locally_trained_model = local_train(initial_model, 0.1, federated_train_data[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
    "def local_eval(model, all_batches):\n",
    "  # TODO(b/120157713): Replace with `tff.sequence_average()` once implemented.\n",
    "    return tff.sequence_sum(\n",
    "        tff.sequence_map(\n",
    "        tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),\n",
    "        all_batches))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_MODEL_TYPE = tff.FederatedType(MODEL_TYPE, tff.SERVER)\n",
    "CLIENT_DATA_TYPE = tff.FederatedType(LOCAL_DATA_TYPE, tff.CLIENTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n",
    "def federated_eval(model, data):\n",
    "    return tff.federated_mean(\n",
    "      tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER)\n",
    "\n",
    "\n",
    "@tff.federated_computation(SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE,\n",
    "                           CLIENT_DATA_TYPE)\n",
    "def federated_train(model, learning_rate, data):\n",
    "    return tff.federated_mean(\n",
    "      tff.federated_map(local_train, [\n",
    "          tff.federated_broadcast(model),\n",
    "          tff.federated_broadcast(learning_rate), data\n",
    "      ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0, loss=21.60552406311035\n",
      "round 1, loss=20.365678787231445\n",
      "round 2, loss=19.27480125427246\n",
      "round 3, loss=18.31110954284668\n"
     ]
    }
   ],
   "source": [
    "model = initial_model\n",
    "learning_rate = 0.1\n",
    "for round_num in range(5):\n",
    "    model = federated_train(model, learning_rate, federated_train_data)\n",
    "    learning_rate = learning_rate * 0.9\n",
    "    loss = federated_eval(model, federated_train_data)\n",
    "    print('round {}, loss={}'.format(round_num, loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
